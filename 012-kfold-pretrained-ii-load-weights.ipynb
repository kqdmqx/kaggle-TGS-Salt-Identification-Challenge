{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use pretrained models\n",
    "\n",
    "https://github.com/qubvel/segmentation_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\envs\\py3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from segmentation_models import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model --pretrained resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "resnet34_model = Unet(backbone_name='resnet34', encoder_weights='imagenet', input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x26e1ca51ba8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26e18aa65c0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26e1ca510f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26e6cfa89b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26e70d83e10>,\n",
       " <keras.layers.core.Activation at 0x26e6d2ef0f0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26e6e69eeb8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x26e6d3005c0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26e6e9bda90>,\n",
       " <keras.layers.core.Activation at 0x26e6e9bd7b8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f7be2bb38>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7bdf4f98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f7a903f28>,\n",
       " <keras.layers.core.Activation at 0x26e1ca146a0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f7bfade48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7bf43c88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7c09be80>,\n",
       " <keras.layers.merge.Add at 0x26f7c0d4dd8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f7c0e5400>,\n",
       " <keras.layers.core.Activation at 0x26f7c10b7b8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f7c15fc18>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7c11bac8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f7c198390>,\n",
       " <keras.layers.core.Activation at 0x26f7f409c18>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f7f422518>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7f48a358>,\n",
       " <keras.layers.merge.Add at 0x26f7f577940>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f7f5d8f28>,\n",
       " <keras.layers.core.Activation at 0x26f7f5c4ef0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f7f5e6588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7f5d8c50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f7f71e5c0>,\n",
       " <keras.layers.core.Activation at 0x26f7f76cef0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f7f7589b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7f7d4c88>,\n",
       " <keras.layers.merge.Add at 0x26f7f8b2f98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f7f8eae48>,\n",
       " <keras.layers.core.Activation at 0x26f7f8ea710>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f7f95bef0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7f903470>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f7fa59b70>,\n",
       " <keras.layers.core.Activation at 0x26f7fabd630>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f7fb39780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7fabd5f8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7fc044e0>,\n",
       " <keras.layers.merge.Add at 0x26f7fc50f60>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f7fc62da0>,\n",
       " <keras.layers.core.Activation at 0x26f7fc41d68>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f7fcfd860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7fc41080>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f7fdc9630>,\n",
       " <keras.layers.core.Activation at 0x26f7fe19b00>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f7fe967b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7fe09128>,\n",
       " <keras.layers.merge.Add at 0x26f7ff5ffd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f7ff9ceb8>,\n",
       " <keras.layers.core.Activation at 0x26f7ff9c780>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f80006c88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f7ffad4e0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f80106be0>,\n",
       " <keras.layers.core.Activation at 0x26f8016b668>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f801e55c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8016bef0>,\n",
       " <keras.layers.merge.Add at 0x26f802ae550>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f802fbfd0>,\n",
       " <keras.layers.core.Activation at 0x26f802fbc88>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f80341eb8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f802ecda0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f804552e8>,\n",
       " <keras.layers.core.Activation at 0x26f8047fa20>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f804a6c88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f804b33c8>,\n",
       " <keras.layers.merge.Add at 0x26f805eab00>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f80639cf8>,\n",
       " <keras.layers.core.Activation at 0x26f80639048>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f8064cdd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f807526d8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f80793780>,\n",
       " <keras.layers.core.Activation at 0x26f807e1c88>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f80802fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f807e1cf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8093e2e8>,\n",
       " <keras.layers.merge.Add at 0x26f80986ba8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f809977f0>,\n",
       " <keras.layers.core.Activation at 0x26f809aaef0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f80a01e48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f80976550>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f80b05fd0>,\n",
       " <keras.layers.core.Activation at 0x26f80b2ea90>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f80b4ecf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f80b60438>,\n",
       " <keras.layers.merge.Add at 0x26f80c96b70>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f80cf9d68>,\n",
       " <keras.layers.core.Activation at 0x26f80cd2fd0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f80d73a20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f80cf9e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f80e3d7f0>,\n",
       " <keras.layers.core.Activation at 0x26f80e8cb38>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f80ed0f60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f80e8cbe0>,\n",
       " <keras.layers.merge.Add at 0x26f80fe9278>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f81010d30>,\n",
       " <keras.layers.core.Activation at 0x26f810346d8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f81045780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f81023550>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f81178e48>,\n",
       " <keras.layers.core.Activation at 0x26f811b4dd8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f8125b940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f811c9390>,\n",
       " <keras.layers.merge.Add at 0x26f81320710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f8136dc88>,\n",
       " <keras.layers.core.Activation at 0x26f8135eac8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f813c5da0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8136d8d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f814c9390>,\n",
       " <keras.layers.core.Activation at 0x26f814f3898>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f81515e48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8157f358>,\n",
       " <keras.layers.merge.Add at 0x26f8165dd68>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f81698f98>,\n",
       " <keras.layers.core.Activation at 0x26f81698f60>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f81717358>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f816ad198>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f81803940>,\n",
       " <keras.layers.core.Activation at 0x26f81866160>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f818d0630>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f81866d30>,\n",
       " <keras.layers.merge.Add at 0x26f819ad2b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f819d57b8>,\n",
       " <keras.layers.core.Activation at 0x26f819f9828>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f81a40f98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f819e96a0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f81b42f98>,\n",
       " <keras.layers.core.Activation at 0x26f81b7cf28>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f81c1eb00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f81b944e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f81ce6860>,\n",
       " <keras.layers.merge.Add at 0x26f81d35a20>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f81d26cf8>,\n",
       " <keras.layers.core.Activation at 0x26f81d26eb8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f81d8ca58>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f81d4c898>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f81eb09b0>,\n",
       " <keras.layers.core.Activation at 0x26f81f11da0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f81f11940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f81f69978>,\n",
       " <keras.layers.merge.Add at 0x26f8205b320>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f82080828>,\n",
       " <keras.layers.core.Activation at 0x26f820a6898>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f820edba8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f82094710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26f821eafd0>,\n",
       " <keras.layers.core.Activation at 0x26f82228f98>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x26f8223c4a8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8224ea20>,\n",
       " <keras.layers.merge.Add at 0x26f823938d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26e6e994ef0>,\n",
       " <keras.layers.core.Activation at 0x26f823e2a20>,\n",
       " <keras.layers.convolutional.UpSampling2D at 0x26f8255a5c0>,\n",
       " <keras.layers.merge.Concatenate at 0x26f8244cb38>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8244cf60>,\n",
       " <keras.layers.core.Activation at 0x26f88d63e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8912a4e0>,\n",
       " <keras.layers.core.Activation at 0x26f88b85400>,\n",
       " <keras.layers.convolutional.UpSampling2D at 0x26f889c6128>,\n",
       " <keras.layers.merge.Concatenate at 0x26f877d1630>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f888c7cc0>,\n",
       " <keras.layers.core.Activation at 0x26f825b65c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8aab0748>,\n",
       " <keras.layers.core.Activation at 0x26f891ffd30>,\n",
       " <keras.layers.convolutional.UpSampling2D at 0x26f8aa86a20>,\n",
       " <keras.layers.merge.Concatenate at 0x26f8a2db7b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8aabfeb8>,\n",
       " <keras.layers.core.Activation at 0x26f8a2f9be0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8a31cf28>,\n",
       " <keras.layers.core.Activation at 0x26f8a31cd30>,\n",
       " <keras.layers.convolutional.UpSampling2D at 0x26f8924e278>,\n",
       " <keras.layers.merge.Concatenate at 0x26f8a30d438>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f892c1dd8>,\n",
       " <keras.layers.core.Activation at 0x26f89270d68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f89348f28>,\n",
       " <keras.layers.core.Activation at 0x26f89348780>,\n",
       " <keras.layers.convolutional.UpSampling2D at 0x26f892d5cc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f8936af28>,\n",
       " <keras.layers.core.Activation at 0x26f8935a358>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f893e09b0>,\n",
       " <keras.layers.core.Activation at 0x26f89402c18>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26f893ec208>,\n",
       " <keras.layers.core.Activation at 0x26f89422dd8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet34_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 64)   0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_padding2d_9 (ZeroPadding2D (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 256)  0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 256)  0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_padding2d_26 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 256)  0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_28[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 256)  0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_30[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_33[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_34[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_16 (Add)                    (None, 8, 8, 512)    0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsample (UpSamp (None, 16, 16, 512)  0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 768)  0           decoder_stage0_upsample[0][0]    \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_conv1 (Conv2D)   (None, 16, 16, 256)  1769728     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_relu1 (Activatio (None, 16, 16, 256)  0           decoder_stage0_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_conv2 (Conv2D)   (None, 16, 16, 256)  590080      decoder_stage0_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_relu2 (Activatio (None, 16, 16, 256)  0           decoder_stage0_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsample (UpSamp (None, 32, 32, 256)  0           decoder_stage0_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 384)  0           decoder_stage1_upsample[0][0]    \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_conv1 (Conv2D)   (None, 32, 32, 128)  442496      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_relu1 (Activatio (None, 32, 32, 128)  0           decoder_stage1_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_conv2 (Conv2D)   (None, 32, 32, 128)  147584      decoder_stage1_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_relu2 (Activatio (None, 32, 32, 128)  0           decoder_stage1_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsample (UpSamp (None, 64, 64, 128)  0           decoder_stage1_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 192)  0           decoder_stage2_upsample[0][0]    \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_conv1 (Conv2D)   (None, 64, 64, 64)   110656      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_relu1 (Activatio (None, 64, 64, 64)   0           decoder_stage2_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_conv2 (Conv2D)   (None, 64, 64, 64)   36928       decoder_stage2_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_relu2 (Activatio (None, 64, 64, 64)   0           decoder_stage2_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsample (UpSamp (None, 128, 128, 64) 0           decoder_stage2_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 128 0           decoder_stage3_upsample[0][0]    \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_conv1 (Conv2D)   (None, 128, 128, 32) 36896       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_relu1 (Activatio (None, 128, 128, 32) 0           decoder_stage3_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_conv2 (Conv2D)   (None, 128, 128, 32) 9248        decoder_stage3_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_relu2 (Activatio (None, 128, 128, 32) 0           decoder_stage3_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsample (UpSamp (None, 256, 256, 32) 0           decoder_stage3_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_conv1 (Conv2D)   (None, 256, 256, 16) 4624        decoder_stage4_upsample[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_relu1 (Activatio (None, 256, 256, 16) 0           decoder_stage4_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_conv2 (Conv2D)   (None, 256, 256, 16) 2320        decoder_stage4_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_relu2 (Activatio (None, 256, 256, 16) 0           decoder_stage4_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, 256, 256, 1)  145         decoder_stage4_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid (Activation)            (None, 256, 256, 1)  0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,453,178\n",
      "Trainable params: 24,437,812\n",
      "Non-trainable params: 15,366\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet34_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Model in module keras.engine.training object:\n",
      "\n",
      "class Model(keras.engine.topology.Container)\n",
      " |  The `Model` class adds training & evaluation routines to a `Container`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Model\n",
      " |      keras.engine.topology.Container\n",
      " |      keras.engine.topology.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          optimizer: String (name of optimizer) or optimizer instance.\n",
      " |              See [optimizers](/optimizers).\n",
      " |          loss: String (name of objective function) or objective function.\n",
      " |              See [losses](/losses).\n",
      " |              If the model has multiple outputs, you can use a different loss\n",
      " |              on each output by passing a dictionary or a list of losses.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model\n",
      " |              during training and testing.\n",
      " |              Typically you will use `metrics=['accuracy']`.\n",
      " |              To specify different metrics for different outputs of a\n",
      " |              multi-output model, you could also pass a dictionary,\n",
      " |              such as `metrics={'output_a': 'accuracy'}`.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions\n",
      " |              of different model outputs.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the *weighted sum* of all individual losses,\n",
      " |              weighted by the `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping\n",
      " |              to the model's outputs. If a tensor, it is expected to map\n",
      " |              output names (strings) to scalar coefficients.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          target_tensors: By default, Keras will create placeholders for the\n",
      " |              model's target, which will be fed with the target data during\n",
      " |              training. If instead you would like to use your own\n",
      " |              target tensors (in turn, Keras will not expect external\n",
      " |              Numpy data for these targets at training time), you\n",
      " |              can specify them via the `target_tensors` argument. It can be\n",
      " |              a single tensor (for a single-output model), a list of tensors,\n",
      " |              or a dict mapping output names to target tensors.\n",
      " |          **kwargs: When using the Theano/CNTK backends, these arguments\n",
      " |              are passed into `K.function`.\n",
      " |              When using the TensorFlow backend,\n",
      " |              these arguments are passed into `tf.Session.run`.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of test data (if the model has a single input),\n",
      " |              or list of Numpy arrays (if the model has multiple inputs).\n",
      " |              If input layers in the model are named, you can also pass a\n",
      " |              dictionary mapping input names to Numpy arrays.\n",
      " |              `x` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Numpy array of target (label) data\n",
      " |              (if the model has a single output),\n",
      " |              or list of Numpy arrays (if the model has multiple outputs).\n",
      " |              If output layers in the model are named, you can also pass a\n",
      " |              dictionary mapping output names to Numpy arrays.\n",
      " |              `y` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per evaluation step.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |          verbose: 0 or 1. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the test samples, used for weighting the loss function.\n",
      " |              You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring the evaluation round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data\n",
      " |      as accepted by `test_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding tuples (inputs, targets)\n",
      " |              or (inputs, targets, sample_weights)\n",
      " |              or an instance of Sequence (keras.utils.Sequence)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          max_queue_size: maximum size for the generator queue\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: if True, use process based threading.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of training data (if the model has a single input),\n",
      " |              or list of Numpy arrays (if the model has multiple inputs).\n",
      " |              If input layers in the model are named, you can also pass a\n",
      " |              dictionary mapping input names to Numpy arrays.\n",
      " |              `x` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Numpy array of target (label) data\n",
      " |              (if the model has a single output),\n",
      " |              or list of Numpy arrays (if the model has multiple outputs).\n",
      " |              If output layers in the model are named, you can also pass a\n",
      " |              dictionary mapping output names to Numpy arrays.\n",
      " |              `y` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling.\n",
      " |          validation_data: tuple `(x_val, y_val)` or tuple\n",
      " |              `(x_val, y_val, val_sample_weights)` on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch').\n",
      " |              'batch' is a special option for dealing with the\n",
      " |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined.\n",
      " |          validation_steps: Only relevant if `steps_per_epoch`\n",
      " |              is specified. Total number of steps (batches of samples)\n",
      " |              to validate before stopping.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Trains the model on data yielded batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      The generator is run in parallel to the model, for efficiency.\n",
      " |      For instance, this allows you to do real-time data augmentation\n",
      " |      on images on CPU in parallel to training your model on GPU.\n",
      " |      \n",
      " |      The use of `keras.utils.Sequence` guarantees the ordering\n",
      " |      and guarantees the single use of every input per epoch when\n",
      " |      using `use_multiprocessing=True`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: A generator or an instance of `Sequence`\n",
      " |              (`keras.utils.Sequence`) object in order to avoid\n",
      " |              duplicate data when using multiprocessing.\n",
      " |              The output of the generator must be either\n",
      " |              - a tuple `(inputs, targets)`\n",
      " |              - a tuple `(inputs, targets, sample_weights)`.\n",
      " |              This tuple (a single output of the generator) makes a single\n",
      " |              batch. Therefore, all arrays in this tuple must have the same\n",
      " |              length (equal to the size of this batch). Different batches\n",
      " |              may have different sizes. For example, the last batch of the\n",
      " |              epoch is commonly smaller than the others, if the size of the\n",
      " |              dataset is not divisible by the batch size.\n",
      " |              The generator is expected to loop over its data\n",
      " |              indefinitely. An epoch finishes when `steps_per_epoch`\n",
      " |              batches have been seen by the model.\n",
      " |          steps_per_epoch: Integer.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before declaring one epoch\n",
      " |              finished and starting the next epoch. It should typically\n",
      " |              be equal to the number of samples of your dataset\n",
      " |              divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire data provided,\n",
      " |              as defined by `steps_per_epoch`.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_data: This can be either\n",
      " |              - a generator for the validation data\n",
      " |              - tuple `(x_val, y_val)`\n",
      " |              - tuple `(x_val, y_val, val_sample_weights)`\n",
      " |              on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |          validation_steps: Only relevant if `validation_data`\n",
      " |              is a generator. Total number of steps (batches of samples)\n",
      " |              to yield from `validation_data` generator before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(validation_data)` as a number of steps.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          max_queue_size: Integer. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. If True, use process based threading.\n",
      " |              If unspecified, `workers` will default to False.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |          shuffle: Boolean. Whether to shuffle the training data\n",
      " |              in batch-sized chunks before each epoch.\n",
      " |              Only used with instances of `Sequence` (`keras.utils.Sequence`).\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |          def generate_arrays_from_file(path):\n",
      " |              while 1:\n",
      " |                  with open(path) as f:\n",
      " |                      for line in f:\n",
      " |                          # create numpy arrays of input data\n",
      " |                          # and labels, from each line in the file\n",
      " |                          x1, x2, y = process_line(line)\n",
      " |                          yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
      " |      \n",
      " |          model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      " |                              steps_per_epoch=10000, epochs=10)\n",
      " |      ```\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: The input data, as a Numpy array\n",
      " |              (or list of Numpy arrays if the model has multiple outputs).\n",
      " |          batch_size: Integer. If unspecified, it will default to 32.\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data as accepted by\n",
      " |      `predict_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding batches of input samples\n",
      " |              or an instance of Sequence (keras.utils.Sequence)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          max_queue_size: Maximum size for the generator queue.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: If `True`, use process based threading.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Input samples, as a Numpy array.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |  \n",
      " |  test_on_batch(self, x, y, sample_weight=None)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of test data,\n",
      " |              or list of Numpy arrays if the model has multiple inputs.\n",
      " |              If all inputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping input names to Numpy arrays.\n",
      " |          y: Numpy array of target data,\n",
      " |              or list of Numpy arrays if the model has multiple outputs.\n",
      " |              If all outputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping output names to Numpy arrays.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile().\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  train_on_batch(self, x, y, sample_weight=None, class_weight=None)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of training data,\n",
      " |              or list of Numpy arrays if the model has multiple inputs.\n",
      " |              If all inputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping input names to Numpy arrays.\n",
      " |          y: Numpy array of target data,\n",
      " |              or list of Numpy arrays if the model has multiple outputs.\n",
      " |              If all outputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping output names to Numpy arrays.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile().\n",
      " |          class_weight: Optional dictionary mapping\n",
      " |              class indices (integers) to\n",
      " |              a weight (float) to apply to the model's loss for the samples\n",
      " |              from this class during training.\n",
      " |              This can be useful to tell the model to \"pay more attention\" to\n",
      " |              samples from an under-represented class.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Container:\n",
      " |  \n",
      " |  __init__(self, inputs, outputs, name=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  call(self, inputs, mask=None)\n",
      " |      Call the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      A model is callable on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Container` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False)\n",
      " |      Loads all layer weights from a HDF5 save file.\n",
      " |      \n",
      " |      If `by_name` is False (default) weights are loaded\n",
      " |      based on the network's topology, meaning the architecture\n",
      " |      should be the same as when the weights were saved.\n",
      " |      Note that layers that don't have weights are not taken\n",
      " |      into account in the topological ordering, so adding or\n",
      " |      removing layers is fine as long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers\n",
      " |      only if they share the same name. This is useful\n",
      " |      for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the weights file to load.\n",
      " |          by_name: Boolean, whether to load weights by name\n",
      " |              or by topological order.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers\n",
      " |              where there is a mismatch in the number of weights,\n",
      " |              or a mismatch in the shape of the weight\n",
      " |              (only valid when `by_name`=True).\n",
      " |      reshape: Reshape weights to fit the layer when the correct number\n",
      " |          of values are present but the shape does not match.\n",
      " |      \n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  run_internal_graph(self, inputs, masks=None)\n",
      " |      Computes output tensors for new inputs.\n",
      " |      \n",
      " |      # Note:\n",
      " |          - Expects `inputs` to be a list (potentially with 1 element).\n",
      " |          - Can be run on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: List of tensors\n",
      " |          masks: List of masks (tensors or None).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Three lists: output_tensors, output_masks, output_shapes\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True)\n",
      " |      Save the model to a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model`\n",
      " |      is a compiled model ready to be used (unless the saved model\n",
      " |      was never compiled in the first place).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True)\n",
      " |      Dumps all layer weights to a HDF5 file.\n",
      " |      \n",
      " |      The weight file has:\n",
      " |          - `layer_names` (attribute), a list of strings\n",
      " |              (ordered names of model layers).\n",
      " |          - For every layer, a `group` named `layer.name`\n",
      " |              - For every such layer group, a group attribute `weight_names`,\n",
      " |                  a list of strings\n",
      " |                  (ordered names of weights tensor of the layer).\n",
      " |              - For every weight in the layer, a dataset\n",
      " |                  storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the model.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: A list of Numpy arrays with shapes and types matching\n",
      " |              the output of `model.get_weights()`.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |              It defaults to `print` (prints to stdout).\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A YAML string.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.topology.Container:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A model instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Container:\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the model's input specs.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  losses\n",
      " |      Retrieve the model's losses.\n",
      " |      \n",
      " |      Will only include losses that are either\n",
      " |      inconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include losses that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of loss tensors.\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |      Retrieve the model's updates.\n",
      " |      \n",
      " |      Will only include updates that are either\n",
      " |      inconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include updates that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  uses_learning_phase\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(resnet34_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model --local 007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION = \"relu\"\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding=\"same\", activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = Activation(ACTIVATION)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = Activation(ACTIVATION)(blockInput)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    return x\n",
    "\n",
    "# Build model\n",
    "def _build_model(input_layer, start_neurons, DropoutRatio = 0.5, padding=\"same\"):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=padding)(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = Activation(ACTIVATION)(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=padding)(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = Activation(ACTIVATION)(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=padding)(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = Activation(ACTIVATION)(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=padding)(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = Activation(ACTIVATION)(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=padding)(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = Activation(ACTIVATION)(convm)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=padding)(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=padding)(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = Activation(ACTIVATION)(uconv4)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=padding)(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=padding)(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = Activation(ACTIVATION)(uconv3)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=padding)(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=padding)(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = Activation(ACTIVATION)(uconv2)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=padding)(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=padding)(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = Activation(ACTIVATION)(uconv1)\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=padding, activation=\"sigmoid\")(uconv1)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "\n",
    "def build_007model(img_size_target):\n",
    "    input_layer = Input((img_size_target, img_size_target, 1))\n",
    "    output_layer = _build_model(input_layer, 32, 0.5, \"same\")\n",
    "\n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 100, 100, 32), (None, 101, 101, 32)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-e29ba44be2d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlocal007_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_007model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-0e69dedc0b9b>\u001b[0m in \u001b[0;36mbuild_007model\u001b[1;34m(img_size_target)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_007model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_size_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_size_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_size_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0moutput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"same\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-0e69dedc0b9b>\u001b[0m in \u001b[0;36m_build_model\u001b[1;34m(input_layer, start_neurons, DropoutRatio, padding)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;31m#deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=padding)(uconv2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mdeconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_neurons\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muconv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0muconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdeconv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0muconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropoutRatio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \"\"\"\n\u001b[1;32m--> 641\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda2\\envs\\py3\\lib\\site-packages\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    352\u001b[0m                              \u001b[1;34m'inputs with matching shapes '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                              \u001b[1;34m'except for the concat axis. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 100, 100, 32), (None, 101, 101, 32)]"
     ]
    }
   ],
   "source": [
    "local007_model = build_007model(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 101, 101, 32) 320         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 101, 101, 32) 0           conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 101, 101, 32) 128         activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 101, 101, 32) 9248        batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 101, 101, 32) 128         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 101, 101, 32) 0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 101, 101, 32) 9248        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 101, 101, 32) 128         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 101, 101, 32) 0           batch_normalization_177[0][0]    \n",
      "                                                                 conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 101, 101, 32) 0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 101, 101, 32) 128         activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 101, 101, 32) 9248        batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 101, 101, 32) 128         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 101, 101, 32) 0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 101, 101, 32) 9248        activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 101, 101, 32) 128         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 101, 101, 32) 0           batch_normalization_180[0][0]    \n",
      "                                                                 add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 101, 101, 32) 0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 50, 50, 32)   0           activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 50, 50, 32)   0           max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 50, 50, 64)   18496       dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 50, 50, 64)   0           conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 50, 50, 64)   256         activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 50, 50, 64)   36928       batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 50, 50, 64)   256         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 50, 50, 64)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 50, 50, 64)   36928       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 50, 50, 64)   256         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 50, 50, 64)   0           batch_normalization_183[0][0]    \n",
      "                                                                 conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 50, 50, 64)   0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 50, 50, 64)   256         activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 50, 50, 64)   36928       batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 50, 50, 64)   256         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 50, 50, 64)   0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 50, 50, 64)   36928       activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 50, 50, 64)   256         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 50, 50, 64)   0           batch_normalization_186[0][0]    \n",
      "                                                                 add_77[0][0]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 50, 50, 64)   0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 25, 25, 64)   0           activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 25, 25, 64)   0           max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 25, 25, 128)  73856       dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 25, 25, 128)  0           conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 25, 25, 128)  512         activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 25, 25, 128)  147584      batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 25, 25, 128)  512         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 25, 25, 128)  0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 25, 25, 128)  147584      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 25, 25, 128)  512         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 25, 25, 128)  0           batch_normalization_189[0][0]    \n",
      "                                                                 conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 25, 25, 128)  0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 25, 25, 128)  512         activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 25, 25, 128)  147584      batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 25, 25, 128)  512         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 25, 25, 128)  0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 25, 25, 128)  147584      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 25, 25, 128)  512         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 25, 25, 128)  0           batch_normalization_192[0][0]    \n",
      "                                                                 add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 25, 25, 128)  0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 12, 12, 128)  0           activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 12, 12, 128)  0           max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 12, 12, 256)  295168      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 12, 12, 256)  0           conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 12, 12, 256)  1024        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 12, 12, 256)  590080      batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 12, 12, 256)  1024        conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 12, 12, 256)  0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 12, 12, 256)  590080      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 12, 12, 256)  1024        conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 12, 12, 256)  0           batch_normalization_195[0][0]    \n",
      "                                                                 conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 12, 12, 256)  0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 12, 12, 256)  1024        activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 12, 12, 256)  590080      batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 12, 12, 256)  1024        conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 12, 12, 256)  0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 12, 12, 256)  590080      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 12, 12, 256)  1024        conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_82 (Add)                    (None, 12, 12, 256)  0           batch_normalization_198[0][0]    \n",
      "                                                                 add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 12, 12, 256)  0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 6, 6, 256)    0           activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 6, 6, 256)    0           max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 6, 6, 512)    1180160     dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 6, 6, 512)    0           conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 6, 6, 512)    2048        activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 6, 6, 512)    2359808     batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 6, 6, 512)    2048        conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 6, 6, 512)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 6, 6, 512)    2359808     activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 6, 6, 512)    2048        conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 6, 6, 512)    0           batch_normalization_201[0][0]    \n",
      "                                                                 conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 6, 6, 512)    0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 6, 6, 512)    2048        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 6, 6, 512)    2359808     batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 6, 6, 512)    2048        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 6, 6, 512)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 6, 6, 512)    2359808     activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 6, 6, 512)    2048        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 6, 6, 512)    0           batch_normalization_204[0][0]    \n",
      "                                                                 add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 6, 6, 512)    0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 12, 12, 256)  1179904     activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 12, 12, 512)  0           conv2d_transpose_12[0][0]        \n",
      "                                                                 activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 12, 12, 512)  0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 12, 12, 256)  1179904     dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 12, 12, 256)  0           conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 12, 12, 256)  1024        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 12, 12, 256)  590080      batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 12, 12, 256)  1024        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 12, 12, 256)  0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 12, 12, 256)  590080      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 12, 12, 256)  1024        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 12, 12, 256)  0           batch_normalization_207[0][0]    \n",
      "                                                                 conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 12, 12, 256)  0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 12, 12, 256)  1024        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 12, 12, 256)  590080      batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 12, 12, 256)  1024        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 12, 12, 256)  0           batch_normalization_209[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 12, 12, 256)  590080      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 12, 12, 256)  1024        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 12, 12, 256)  0           batch_normalization_210[0][0]    \n",
      "                                                                 add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 12, 12, 256)  0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 25, 25, 128)  295040      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 25, 25, 256)  0           conv2d_transpose_13[0][0]        \n",
      "                                                                 activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 25, 25, 256)  0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 25, 25, 128)  295040      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 25, 25, 128)  0           conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 25, 25, 128)  512         activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 25, 25, 128)  147584      batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 25, 25, 128)  512         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 25, 25, 128)  0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 25, 25, 128)  147584      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 25, 25, 128)  512         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 25, 25, 128)  0           batch_normalization_213[0][0]    \n",
      "                                                                 conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 25, 25, 128)  0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 25, 25, 128)  512         activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 25, 25, 128)  147584      batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 25, 25, 128)  512         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 25, 25, 128)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 25, 25, 128)  147584      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 25, 25, 128)  512         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 25, 25, 128)  0           batch_normalization_216[0][0]    \n",
      "                                                                 add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 25, 25, 128)  0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 50, 50, 64)   73792       activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 50, 50, 128)  0           conv2d_transpose_14[0][0]        \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 50, 50, 128)  0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 50, 50, 64)   73792       dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 50, 50, 64)   0           conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 50, 50, 64)   256         activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 50, 50, 64)   36928       batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 50, 50, 64)   256         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 50, 50, 64)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 50, 50, 64)   36928       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 50, 50, 64)   256         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 50, 50, 64)   0           batch_normalization_219[0][0]    \n",
      "                                                                 conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 50, 50, 64)   0           add_89[0][0]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 50, 50, 64)   256         activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 50, 50, 64)   36928       batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 50, 50, 64)   256         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 50, 50, 64)   0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 50, 50, 64)   36928       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 50, 50, 64)   256         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 50, 50, 64)   0           batch_normalization_222[0][0]    \n",
      "                                                                 add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 50, 50, 64)   0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 101, 101, 32) 18464       activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 101, 101, 64) 0           conv2d_transpose_15[0][0]        \n",
      "                                                                 activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 101, 101, 64) 0           concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 101, 101, 32) 18464       dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 101, 101, 32) 0           conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 101, 101, 32) 128         activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 101, 101, 32) 9248        batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 101, 101, 32) 128         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 101, 101, 32) 0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 101, 101, 32) 9248        activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 101, 101, 32) 128         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 101, 101, 32) 0           batch_normalization_225[0][0]    \n",
      "                                                                 conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 101, 101, 32) 0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 101, 101, 32) 128         activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 101, 101, 32) 9248        batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 101, 101, 32) 128         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 101, 101, 32) 0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 101, 101, 32) 9248        activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 101, 101, 32) 128         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 101, 101, 32) 0           batch_normalization_228[0][0]    \n",
      "                                                                 add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 101, 101, 32) 0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 101, 101, 32) 0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 101, 101, 1)  33          dropout_36[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,447,713\n",
      "Trainable params: 20,430,049\n",
      "Non-trainable params: 17,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "local007_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the md5 file hash does not match the original value of db3b217156506944570ac220086f09b6 so we will re-download the data.\n",
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet50_imagenet_1000_no_top.h5\n",
      "94593024/94592056 [==============================] - ETA: 1:42:0 - ETA: 51:19  - ETA: 41:1 - ETA: 28:3 - ETA: 23:4 - ETA: 16:0 - ETA: 16:2 - ETA: 13:3 - ETA: 13:4 - ETA: 12:3 - ETA: 10:3 - ETA: 10:5 - ETA: 8:4 - ETA: 9: - ETA: 7: - ETA: 7: - ETA: 6: - ETA: 5: - ETA: 5: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 1: - ETA: 48s - ETA: 47 - ETA: 46 - ETA: 45 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 43 - ETA: 42 - ETA: 41 - ETA: 41 - ETA: 40 - ETA: 40 - ETA: 39 - ETA: 38 - ETA: 38 - ETA: 37 - ETA: 37 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 25s 0us/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Unet(backbone_name='resnet50', encoder_weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train --fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "index.shape: (3196,) (804,)\n",
      "mode: 009-model-resnet-fold-0.hdf5\n",
      "log: 009-log-resnet-fold-0.csv\n",
      "load model done.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\envs\\py3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90036, saving model to 009-model-resnet-fold-0.hdf5\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90036 to 0.90884, saving model to 009-model-resnet-fold-0.hdf5\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90884 to 0.93270, saving model to 009-model-resnet-fold-0.hdf5\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.93270 to 0.93446, saving model to 009-model-resnet-fold-0.hdf5\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.93446 to 0.93620, saving model to 009-model-resnet-fold-0.hdf5\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 00018: val_acc did not improve\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.93620 to 0.93685, saving model to 009-model-resnet-fold-0.hdf5\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 00021: val_acc did not improve\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 00023: val_acc did not improve\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.93685 to 0.93744, saving model to 009-model-resnet-fold-0.hdf5\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 00027: val_acc did not improve\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 00028: val_acc did not improve\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 00030: val_acc did not improve\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 00032: val_acc did not improve\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 00033: val_acc did not improve\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 00034: val_acc did not improve\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 00035: val_acc did not improve\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 00036: val_acc did not improve\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 00038: val_acc did not improve\n",
      "Epoch 39/200\n",
      "\n",
      "Epoch 00039: val_acc did not improve\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 00040: val_acc did not improve\n",
      "Epoch 41/200\n",
      "\n",
      "Epoch 00041: val_acc did not improve\n",
      "Epoch 42/200\n",
      "\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 43/200\n",
      "\n",
      "Epoch 00043: val_acc did not improve\n",
      "Epoch 44/200\n",
      "\n",
      "Epoch 00044: val_acc did not improve\n",
      "Epoch 00044: early stopping\n",
      "Wall time: 1h 14min 19s\n"
     ]
    }
   ],
   "source": [
    "exp_code = \"009\"\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(kfold_index):\n",
    "    print(\"fold:\", i)\n",
    "    print(\"index.shape:\", train_idx.shape, valid_idx.shape)\n",
    "    \n",
    "    model_filepath = \"{}-model-resnet-fold-{}.hdf5\".format(exp_code, i)\n",
    "    log_filepath = \"{}-log-resnet-fold-{}.csv\".format(exp_code, i)\n",
    "    \n",
    "    print(\"mode:\", model_filepath)\n",
    "    print(\"log:\", log_filepath)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_acc', mode = 'max',patience=20, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(model_filepath, monitor='val_acc', mode = 'max', save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode = 'max', factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "    model_logger = CSVLogger(log_filepath, separator=',', append=False)\n",
    "\n",
    "    epochs = 200\n",
    "    batch_size = 16\n",
    "    X_train = X[train_idx, :]\n",
    "    X_valid = X[valid_idx, :]\n",
    "    Y_train = Y[train_idx, :]\n",
    "    Y_valid = Y[valid_idx, :]\n",
    "    # optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    # model.fit(X_train, Y_train,\n",
    "    #           validation_data=[X_valid, Y_valid], \n",
    "    #           epochs=epochs,\n",
    "    #           batch_size=batch_size,\n",
    "    #           callbacks=[early_stopping, model_checkpoint, reduce_lr, model_logger], \n",
    "    #           verbose=200)\n",
    "    \n",
    "    # break\n",
    "\n",
    "    def train():\n",
    "        model = Unet(backbone_name='resnet50', encoder_weights='imagenet')\n",
    "        model.compile(\"adam\", 'binary_crossentropy', ['acc'])\n",
    "        print(\"load model done.\")\n",
    "\n",
    "        model.fit_generator(generate_batch_data_random(X_train, Y_train, batch_size),\n",
    "                            validation_data=generate_batch_data(X_valid, Y_valid, 50), \n",
    "                            epochs=epochs,\n",
    "                            steps_per_epoch=100,\n",
    "                            callbacks=[early_stopping, model_checkpoint, reduce_lr, model_logger],\n",
    "                            validation_steps=16,\n",
    "                            verbose=200)\n",
    "        keras.backend.clear_session()\n",
    "        \n",
    "    %time train()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "index.shape: (3196,) (804,)\n",
      "mode: 007-model-resnet-fold-0.hdf5\n",
      "log: 007-log-resnet-fold-0.csv\n",
      "data.shape: (6392, 101, 101, 1) (6392, 101, 101, 1) (804, 101, 101, 1) (804, 101, 101, 1)\n",
      "build model.\n",
      "Train on 6392 samples, validate on 804 samples\n",
      "Epoch 1/200\n",
      "Epoch 00001: val_acc improved from -inf to 0.24839, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 2/200\n",
      "Epoch 00002: val_acc improved from 0.24839 to 0.65560, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 3/200\n",
      "Epoch 00003: val_acc improved from 0.65560 to 0.89232, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 4/200\n",
      "Epoch 00004: val_acc improved from 0.89232 to 0.90095, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 5/200\n",
      "Epoch 00005: val_acc improved from 0.90095 to 0.91183, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 6/200\n",
      "Epoch 00006: val_acc improved from 0.91183 to 0.91594, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 7/200\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/200\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/200\n",
      "Epoch 00009: val_acc improved from 0.91594 to 0.93239, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 10/200\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/200\n",
      "Epoch 00011: val_acc improved from 0.93239 to 0.93882, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 12/200\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/200\n",
      "Epoch 00013: val_acc improved from 0.93882 to 0.94069, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 14/200\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/200\n",
      "Epoch 00015: val_acc improved from 0.94069 to 0.94161, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 16/200\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/200\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 18/200\n",
      "Epoch 00018: val_acc improved from 0.94161 to 0.94343, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 19/200\n",
      "Epoch 00019: val_acc improved from 0.94343 to 0.94439, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 20/200\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/200\n",
      "Epoch 00021: val_acc did not improve\n",
      "Epoch 22/200\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/200\n",
      "Epoch 00023: val_acc did not improve\n",
      "Epoch 24/200\n",
      "Epoch 00024: val_acc did not improve\n",
      "Epoch 25/200\n",
      "Epoch 00025: val_acc improved from 0.94439 to 0.94472, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 26/200\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/200\n",
      "Epoch 00027: val_acc improved from 0.94472 to 0.94616, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 28/200\n",
      "Epoch 00028: val_acc did not improve\n",
      "Epoch 29/200\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/200\n",
      "Epoch 00030: val_acc did not improve\n",
      "Epoch 31/200\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/200\n",
      "Epoch 00032: val_acc did not improve\n",
      "Epoch 33/200\n",
      "Epoch 00033: val_acc did not improve\n",
      "\n",
      "Epoch 00033: reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 34/200\n",
      "Epoch 00034: val_acc improved from 0.94616 to 0.94648, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 35/200\n",
      "Epoch 00035: val_acc improved from 0.94648 to 0.95082, saving model to 007-model-resnet-fold-0.hdf5\n",
      "Epoch 36/200\n",
      "Epoch 00036: val_acc did not improve\n",
      "Epoch 37/200\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/200\n",
      "Epoch 00038: val_acc did not improve\n",
      "Epoch 39/200\n",
      "Epoch 00039: val_acc did not improve\n",
      "Epoch 40/200\n",
      "Epoch 00040: val_acc did not improve\n",
      "Epoch 41/200\n",
      "Epoch 00041: val_acc did not improve\n",
      "\n",
      "Epoch 00041: reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 42/200\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 43/200\n",
      "Epoch 00043: val_acc did not improve\n",
      "Epoch 44/200\n",
      "Epoch 00044: val_acc did not improve\n",
      "Epoch 45/200\n",
      "Epoch 00045: val_acc did not improve\n",
      "Epoch 46/200\n",
      "Epoch 00046: val_acc did not improve\n",
      "\n",
      "Epoch 00046: reducing learning rate to 1e-05.\n",
      "Epoch 47/200\n",
      "Epoch 00047: val_acc did not improve\n",
      "Epoch 48/200\n",
      "Epoch 00048: val_acc did not improve\n",
      "Epoch 49/200\n",
      "Epoch 00049: val_acc did not improve\n",
      "Epoch 50/200\n",
      "Epoch 00050: val_acc did not improve\n",
      "Epoch 51/200\n",
      "Epoch 00051: val_acc did not improve\n",
      "Epoch 52/200\n",
      "Epoch 00052: val_acc did not improve\n",
      "Epoch 53/200\n",
      "Epoch 00053: val_acc did not improve\n",
      "Epoch 54/200\n",
      "Epoch 00054: val_acc did not improve\n",
      "Epoch 55/200\n",
      "Epoch 00055: val_acc did not improve\n",
      "Epoch 00055: early stopping\n",
      "Wall time: 1h 20min 40s\n",
      "fold: 1\n",
      "index.shape: (3199,) (801,)\n",
      "mode: 007-model-resnet-fold-1.hdf5\n",
      "log: 007-log-resnet-fold-1.csv\n",
      "data.shape: (6398, 101, 101, 1) (6398, 101, 101, 1) (801, 101, 101, 1) (801, 101, 101, 1)\n",
      "build model.\n",
      "Train on 6398 samples, validate on 801 samples\n",
      "Epoch 1/200\n",
      "Epoch 00001: val_acc improved from -inf to 0.24889, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 2/200\n",
      "Epoch 00002: val_acc improved from 0.24889 to 0.52023, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 3/200\n",
      "Epoch 00003: val_acc improved from 0.52023 to 0.85298, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 4/200\n",
      "Epoch 00004: val_acc improved from 0.85298 to 0.91021, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 5/200\n",
      "Epoch 00005: val_acc improved from 0.91021 to 0.92879, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 6/200\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/200\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/200\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/200\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/200\n",
      "Epoch 00010: val_acc improved from 0.92879 to 0.94152, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 11/200\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 12/200\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/200\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/200\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/200\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/200\n",
      "Epoch 00016: val_acc did not improve\n",
      "\n",
      "Epoch 00016: reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 17/200\n",
      "Epoch 00017: val_acc improved from 0.94152 to 0.94857, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 18/200\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/200\n",
      "Epoch 00019: val_acc improved from 0.94857 to 0.94870, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 20/200\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/200\n",
      "Epoch 00021: val_acc improved from 0.94870 to 0.95026, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 22/200\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/200\n",
      "Epoch 00023: val_acc improved from 0.95026 to 0.95337, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 24/200\n",
      "Epoch 00024: val_acc did not improve\n",
      "Epoch 25/200\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/200\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/200\n",
      "Epoch 00027: val_acc did not improve\n",
      "Epoch 28/200\n",
      "Epoch 00028: val_acc did not improve\n",
      "Epoch 29/200\n",
      "Epoch 00029: val_acc did not improve\n",
      "\n",
      "Epoch 00029: reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 30/200\n",
      "Epoch 00030: val_acc did not improve\n",
      "Epoch 31/200\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/200\n",
      "Epoch 00032: val_acc did not improve\n",
      "Epoch 33/200\n",
      "Epoch 00033: val_acc did not improve\n",
      "Epoch 34/200\n",
      "Epoch 00034: val_acc improved from 0.95337 to 0.95377, saving model to 007-model-resnet-fold-1.hdf5\n",
      "Epoch 35/200\n",
      "Epoch 00035: val_acc did not improve\n",
      "Epoch 36/200\n",
      "Epoch 00036: val_acc did not improve\n",
      "Epoch 37/200\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/200\n",
      "Epoch 00038: val_acc did not improve\n",
      "Epoch 39/200\n",
      "Epoch 00039: val_acc did not improve\n",
      "Epoch 40/200\n",
      "Epoch 00040: val_acc did not improve\n",
      "\n",
      "Epoch 00040: reducing learning rate to 1e-05.\n",
      "Epoch 41/200\n",
      "Epoch 00041: val_acc did not improve\n",
      "Epoch 42/200\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 43/200\n",
      "Epoch 00043: val_acc did not improve\n",
      "Epoch 44/200\n",
      "Epoch 00044: val_acc did not improve\n",
      "Epoch 45/200\n",
      "Epoch 00045: val_acc did not improve\n",
      "Epoch 46/200\n",
      "Epoch 00046: val_acc did not improve\n",
      "Epoch 47/200\n",
      "Epoch 00047: val_acc did not improve\n",
      "Epoch 48/200\n",
      "Epoch 00048: val_acc did not improve\n",
      "Epoch 49/200\n",
      "Epoch 00049: val_acc did not improve\n",
      "Epoch 50/200\n",
      "Epoch 00050: val_acc did not improve\n",
      "Epoch 51/200\n",
      "Epoch 00051: val_acc did not improve\n",
      "Epoch 52/200\n",
      "Epoch 00052: val_acc did not improve\n",
      "Epoch 53/200\n",
      "Epoch 00053: val_acc did not improve\n",
      "Epoch 54/200\n",
      "Epoch 00054: val_acc did not improve\n",
      "Epoch 00054: early stopping\n",
      "Wall time: 1h 19min 14s\n",
      "fold: 2\n",
      "index.shape: (3200,) (800,)\n",
      "mode: 007-model-resnet-fold-2.hdf5\n",
      "log: 007-log-resnet-fold-2.csv\n",
      "data.shape: (6400, 101, 101, 1) (6400, 101, 101, 1) (800, 101, 101, 1) (800, 101, 101, 1)\n",
      "build model.\n",
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      "Epoch 00001: val_acc improved from -inf to 0.24803, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 2/200\n",
      "Epoch 00002: val_acc improved from 0.24803 to 0.49422, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 3/200\n",
      "Epoch 00003: val_acc improved from 0.49422 to 0.62818, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 4/200\n",
      "Epoch 00004: val_acc improved from 0.62818 to 0.82511, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 5/200\n",
      "Epoch 00005: val_acc improved from 0.82511 to 0.92061, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 6/200\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/200\n",
      "Epoch 00007: val_acc improved from 0.92061 to 0.92849, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 8/200\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/200\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/200\n",
      "Epoch 00010: val_acc improved from 0.92849 to 0.93133, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 11/200\n",
      "Epoch 00011: val_acc improved from 0.93133 to 0.93622, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 12/200\n",
      "Epoch 00012: val_acc improved from 0.93622 to 0.93782, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 13/200\n",
      "Epoch 00013: val_acc improved from 0.93782 to 0.93999, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 14/200\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/200\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/200\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/200\n",
      "Epoch 00017: val_acc improved from 0.93999 to 0.94090, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 18/200\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/200\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/200\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/200\n",
      "Epoch 00021: val_acc improved from 0.94090 to 0.94702, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 22/200\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/200\n",
      "Epoch 00023: val_acc did not improve\n",
      "Epoch 24/200\n",
      "Epoch 00024: val_acc did not improve\n",
      "Epoch 25/200\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/200\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/200\n",
      "Epoch 00027: val_acc did not improve\n",
      "\n",
      "Epoch 00027: reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 28/200\n",
      "Epoch 00028: val_acc improved from 0.94702 to 0.95359, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 29/200\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/200\n",
      "Epoch 00030: val_acc did not improve\n",
      "Epoch 31/200\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/200\n",
      "Epoch 00032: val_acc improved from 0.95359 to 0.95410, saving model to 007-model-resnet-fold-2.hdf5\n",
      "Epoch 33/200\n",
      "Epoch 00033: val_acc did not improve\n",
      "Epoch 34/200\n",
      "Epoch 00034: val_acc did not improve\n",
      "Epoch 35/200\n",
      "Epoch 00035: val_acc did not improve\n",
      "Epoch 36/200\n",
      "Epoch 00036: val_acc did not improve\n",
      "Epoch 37/200\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/200\n",
      "Epoch 00038: val_acc did not improve\n",
      "\n",
      "Epoch 00038: reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 39/200\n",
      "Epoch 00039: val_acc did not improve\n",
      "Epoch 40/200\n",
      "Epoch 00040: val_acc did not improve\n",
      "Epoch 41/200\n",
      "Epoch 00041: val_acc did not improve\n",
      "Epoch 42/200\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 43/200\n",
      "Epoch 00043: val_acc did not improve\n",
      "\n",
      "Epoch 00043: reducing learning rate to 1e-05.\n",
      "Epoch 44/200\n",
      "Epoch 00044: val_acc did not improve\n",
      "Epoch 45/200\n",
      "Epoch 00045: val_acc did not improve\n",
      "Epoch 46/200\n",
      "Epoch 00046: val_acc did not improve\n",
      "Epoch 47/200\n",
      "Epoch 00047: val_acc did not improve\n",
      "Epoch 48/200\n",
      "Epoch 00048: val_acc did not improve\n",
      "Epoch 49/200\n",
      "Epoch 00049: val_acc did not improve\n",
      "Epoch 50/200\n",
      "Epoch 00050: val_acc did not improve\n",
      "Epoch 51/200\n",
      "Epoch 00051: val_acc did not improve\n",
      "Epoch 52/200\n",
      "Epoch 00052: val_acc did not improve\n",
      "Epoch 00052: early stopping\n",
      "Wall time: 1h 16min 25s\n",
      "fold: 3\n",
      "index.shape: (3201,) (799,)\n",
      "mode: 007-model-resnet-fold-3.hdf5\n",
      "log: 007-log-resnet-fold-3.csv\n",
      "data.shape: (6402, 101, 101, 1) (6402, 101, 101, 1) (799, 101, 101, 1) (799, 101, 101, 1)\n",
      "build model.\n",
      "Train on 6402 samples, validate on 799 samples\n",
      "Epoch 1/200\n",
      "Epoch 00001: val_acc improved from -inf to 0.24938, saving model to 007-model-resnet-fold-3.hdf5\n",
      "Epoch 2/200\n",
      "Epoch 00002: val_acc improved from 0.24938 to 0.61175, saving model to 007-model-resnet-fold-3.hdf5\n",
      "Epoch 3/200\n",
      "Epoch 00003: val_acc improved from 0.61175 to 0.63690, saving model to 007-model-resnet-fold-3.hdf5\n",
      "Epoch 4/200\n",
      "Epoch 00004: val_acc improved from 0.63690 to 0.90091, saving model to 007-model-resnet-fold-3.hdf5\n",
      "Epoch 5/200\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/200\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/200\n",
      "Epoch 00007: val_acc improved from 0.90091 to 0.93271, saving model to 007-model-resnet-fold-3.hdf5\n",
      "Epoch 8/200\n",
      "Epoch 00008: val_acc improved from 0.93271 to 0.93321, saving model to 007-model-resnet-fold-3.hdf5\n",
      "Epoch 9/200\n",
      "Epoch 00009: val_acc improved from 0.93321 to 0.93933, saving model to 007-model-resnet-fold-3.hdf5\n",
      "Epoch 10/200\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/200\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 12/200\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/200\n",
      "Epoch 00013: val_acc improved from 0.93933 to 0.94125, saving model to 007-model-resnet-fold-3.hdf5\n",
      "Epoch 14/200\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/200\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/200\n",
      "Epoch 00016: val_acc improved from 0.94125 to 0.94480, saving model to 007-model-resnet-fold-3.hdf5\n",
      "Epoch 17/200\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 18/200\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/200\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/200\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/200\n",
      "Epoch 00021: val_acc did not improve\n",
      "Epoch 22/200\n",
      "Epoch 00022: val_acc improved from 0.94480 to 0.94827, saving model to 007-model-resnet-fold-3.hdf5\n",
      "Epoch 23/200\n",
      "Epoch 00023: val_acc did not improve\n",
      "Epoch 24/200\n",
      "Epoch 00024: val_acc did not improve\n",
      "Epoch 25/200\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/200\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/200\n",
      "Epoch 00027: val_acc did not improve\n",
      "Epoch 28/200\n",
      "Epoch 00028: val_acc did not improve\n",
      "\n",
      "Epoch 00028: reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 29/200\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/200\n",
      "Epoch 00030: val_acc did not improve\n",
      "Epoch 31/200\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/200\n",
      "Epoch 00032: val_acc did not improve\n",
      "Epoch 33/200\n",
      "Epoch 00033: val_acc did not improve\n",
      "\n",
      "Epoch 00033: reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 34/200\n",
      "Epoch 00034: val_acc did not improve\n",
      "Epoch 35/200\n",
      "Epoch 00035: val_acc did not improve\n",
      "Epoch 36/200\n",
      "Epoch 00036: val_acc did not improve\n",
      "Epoch 37/200\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/200\n",
      "Epoch 00038: val_acc did not improve\n",
      "\n",
      "Epoch 00038: reducing learning rate to 1e-05.\n",
      "Epoch 39/200\n",
      "Epoch 00039: val_acc did not improve\n",
      "Epoch 40/200\n",
      "Epoch 00040: val_acc did not improve\n",
      "Epoch 41/200\n",
      "Epoch 00041: val_acc did not improve\n",
      "Epoch 42/200\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 00042: early stopping\n",
      "Wall time: 1h 2min 28s\n",
      "fold: 4\n",
      "index.shape: (3204,) (796,)\n",
      "mode: 007-model-resnet-fold-4.hdf5\n",
      "log: 007-log-resnet-fold-4.csv\n",
      "data.shape: (6408, 101, 101, 1) (6408, 101, 101, 1) (796, 101, 101, 1) (796, 101, 101, 1)\n",
      "build model.\n",
      "Train on 6408 samples, validate on 796 samples\n",
      "Epoch 1/200\n",
      "Epoch 00001: val_acc improved from -inf to 0.24958, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 2/200\n",
      "Epoch 00002: val_acc improved from 0.24958 to 0.34460, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 3/200\n",
      "Epoch 00003: val_acc improved from 0.34460 to 0.70076, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 4/200\n",
      "Epoch 00004: val_acc improved from 0.70076 to 0.88755, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 5/200\n",
      "Epoch 00005: val_acc improved from 0.88755 to 0.90803, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 6/200\n",
      "Epoch 00006: val_acc improved from 0.90803 to 0.92795, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 7/200\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/200\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/200\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: val_acc improved from 0.92795 to 0.93912, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 11/200\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 12/200\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/200\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/200\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/200\n",
      "Epoch 00015: val_acc improved from 0.93912 to 0.94232, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 16/200\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/200\n",
      "Epoch 00017: val_acc improved from 0.94232 to 0.94579, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 18/200\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/200\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/200\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/200\n",
      "Epoch 00021: val_acc did not improve\n",
      "Epoch 22/200\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/200\n",
      "Epoch 00023: val_acc did not improve\n",
      "\n",
      "Epoch 00023: reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 24/200\n",
      "Epoch 00024: val_acc improved from 0.94579 to 0.94947, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 25/200\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/200\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/200\n",
      "Epoch 00027: val_acc did not improve\n",
      "Epoch 28/200\n",
      "Epoch 00028: val_acc did not improve\n",
      "Epoch 29/200\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/200\n",
      "Epoch 00030: val_acc improved from 0.94947 to 0.95244, saving model to 007-model-resnet-fold-4.hdf5\n",
      "Epoch 31/200\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/200\n",
      "Epoch 00032: val_acc did not improve\n",
      "Epoch 33/200\n",
      "Epoch 00033: val_acc did not improve\n",
      "Epoch 34/200\n",
      "Epoch 00034: val_acc did not improve\n",
      "Epoch 35/200\n",
      "Epoch 00035: val_acc did not improve\n",
      "Epoch 36/200\n",
      "Epoch 00036: val_acc did not improve\n",
      "\n",
      "Epoch 00036: reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 37/200\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/200\n",
      "Epoch 00038: val_acc did not improve\n",
      "Epoch 39/200\n",
      "Epoch 00039: val_acc did not improve\n",
      "Epoch 40/200\n",
      "Epoch 00040: val_acc did not improve\n",
      "Epoch 41/200\n",
      "Epoch 00041: val_acc did not improve\n",
      "\n",
      "Epoch 00041: reducing learning rate to 1e-05.\n",
      "Epoch 42/200\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 43/200\n",
      "Epoch 00043: val_acc did not improve\n",
      "Epoch 44/200\n",
      "Epoch 00044: val_acc did not improve\n",
      "Epoch 45/200\n",
      "Epoch 00045: val_acc did not improve\n",
      "Epoch 46/200\n",
      "Epoch 00046: val_acc did not improve\n",
      "Epoch 47/200\n",
      "Epoch 00047: val_acc did not improve\n",
      "Epoch 48/200\n",
      "Epoch 00048: val_acc did not improve\n",
      "Epoch 49/200\n",
      "Epoch 00049: val_acc did not improve\n",
      "Epoch 50/200\n",
      "Epoch 00050: val_acc did not improve\n",
      "Epoch 00050: early stopping\n",
      "Wall time: 1h 14min 17s\n"
     ]
    }
   ],
   "source": [
    "exp_code = \"009\"\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(kfold_index):\n",
    "    print(\"fold:\", i)\n",
    "    print(\"index.shape:\", train_idx.shape, valid_idx.shape)\n",
    "    \n",
    "    model_filepath = \"{}-model-resnet-fold-{}.hdf5\".format(exp_code, i)\n",
    "    log_filepath = \"{}-log-resnet-fold-{}.csv\".format(exp_code, i)\n",
    "    \n",
    "    print(\"mode:\", model_filepath)\n",
    "    print(\"log:\", log_filepath)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_acc', mode = 'max',patience=20, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(model_filepath, monitor='val_acc', mode = 'max', save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode = 'max', factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "    model_logger = CSVLogger(log_filepath, separator=',', append=False)\n",
    "\n",
    "    epochs = 200\n",
    "    batch_size = 32\n",
    "    \n",
    "    X_train = X[train_idx, :]\n",
    "    X_valid = X[valid_idx, :]\n",
    "    Y_train = Y[train_idx, :]\n",
    "    Y_valid = Y[valid_idx, :]\n",
    "    \n",
    "    X_train = np.append(X_train, [np.fliplr(x) for x in X_train], axis=0)\n",
    "    Y_train = np.append(Y_train, [np.fliplr(x) for x in Y_train], axis=0)\n",
    "    \n",
    "    print(\"data.shape:\", X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape)\n",
    "    \n",
    "    model = build_model(img_size_target=101)\n",
    "    print(\"build model.\")\n",
    "    \n",
    "    def train():\n",
    "\n",
    "        return model.fit(X_train, Y_train,\n",
    "                         validation_data=[X_valid, Y_valid], \n",
    "                         epochs=epochs,\n",
    "                         batch_size=batch_size,\n",
    "                         callbacks=[early_stopping, model_checkpoint, reduce_lr, model_logger], \n",
    "                         verbose=200)\n",
    "    \n",
    "    %time train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\007-model-resnet-fold-0.hdf5',\n",
       " '.\\\\007-model-resnet-fold-1.hdf5',\n",
       " '.\\\\007-model-resnet-fold-2.hdf5',\n",
       " '.\\\\007-model-resnet-fold-3.hdf5',\n",
       " '.\\\\007-model-resnet-fold-4.hdf5']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_result(model, x_test, img_size_target): # predict both orginal and reflect x\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(a) for a in model.predict(np.array([np.fliplr(x) for x in x_test])).reshape(-1, img_size_target, img_size_target)])\n",
    "    return preds_test / 2.0\n",
    "\n",
    "def filter_image(img):\n",
    "    if img.sum() < 100:\n",
    "        return np.zeros(img.shape)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "import glob\n",
    "glob.glob(\"./007*.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n",
    "\n",
    "def iou(img_true, img_pred):\n",
    "    i = np.sum((img_true*img_pred) >0)\n",
    "    u = np.sum((img_true + img_pred) >0)\n",
    "    if u == 0:\n",
    "        return u\n",
    "    return i/u\n",
    "\n",
    "def iou_metric(imgs_true, imgs_pred):\n",
    "    num_images = len(imgs_true)\n",
    "    scores = np.zeros(num_images)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        if imgs_true[i].sum() == imgs_pred[i].sum() == 0:\n",
    "            scores[i] = 1\n",
    "        else:\n",
    "            scores[i] = (thresholds <= iou(imgs_true[i], imgs_pred[i])).mean()\n",
    "            \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196,) (804,)\n",
      ".\\007-model-resnet-fold-0.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7b9d6839684f25a5af5759ef9936fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAETCAYAAAAh/OHhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf00347e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3199,) (801,)\n",
      ".\\007-model-resnet-fold-1.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b55ae80e574e2da65df5c16b90fb13"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAETCAYAAADH1SqlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf25502c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200,) (800,)\n",
      ".\\007-model-resnet-fold-2.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6824f657c4c04a3cb128f0323583caac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAETCAYAAAD3WTuEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf4a1fee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3201,) (799,)\n",
      ".\\007-model-resnet-fold-3.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8126a3c1e941e99f9db83a5f0e5885"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAETCAYAAADZHBoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf723bd978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3204,) (796,)\n",
      ".\\007-model-resnet-fold-4.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2020e2498e1482a963dd1a5dfb3cb06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAETCAYAAADH1SqlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFXJYmJlZIYeFmZkVcliYmVmhX04EVqUH5/MIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf9358bb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8459431893415525 0.0038845992128691514\n"
     ]
    }
   ],
   "source": [
    "model_filepaths = [\n",
    "    '.\\\\007-model-resnet-fold-0.hdf5',\n",
    "    '.\\\\007-model-resnet-fold-1.hdf5',\n",
    "    '.\\\\007-model-resnet-fold-2.hdf5',\n",
    "    '.\\\\007-model-resnet-fold-3.hdf5',\n",
    "    '.\\\\007-model-resnet-fold-4.hdf5'\n",
    "]\n",
    "\n",
    "threshold_best_stack = []\n",
    "iou_best_stack = []\n",
    "\n",
    "for (train_idx, valid_idx), model_filepath in zip(kfold_index, model_filepaths):\n",
    "    print(train_idx.shape, valid_idx.shape)\n",
    "    print(model_filepath)\n",
    "    \n",
    "    ## preds_valid\n",
    "    X_valid = X[valid_idx, :]\n",
    "    Y_valid = Y[valid_idx, :]\n",
    "    \n",
    "    model = load_model(model_filepath)\n",
    "    preds_valid = predict_result(model, X_valid, img_size_target)\n",
    "    \n",
    "    ## Scoring for last model\n",
    "    thresholds = np.linspace(0.3, 0.7, 31)\n",
    "    ious = np.array([iou_metric(Y_valid.reshape((-1, img_size_target, img_size_target)), [filter_image(img) for img in preds_valid > threshold]) for threshold in tqdm_notebook(thresholds)])\n",
    "    \n",
    "    threshold_best_index = np.argmax(ious) \n",
    "    iou_best = ious[threshold_best_index]\n",
    "    threshold_best = thresholds[threshold_best_index]\n",
    "    \n",
    "    threshold_best_stack.append(threshold_best)\n",
    "    iou_best_stack.append(iou_best)\n",
    "\n",
    "    plt.plot(thresholds, ious)\n",
    "    plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"IoU\")\n",
    "    plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "print(np.mean(iou_best_stack), np.std(iou_best_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict test\n",
    "\n",
    "threshold_best_stack = [0.5133333333333333, 0.38, 0.43333333333333335, 0.36666666666666664, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size_target = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_result(model, x_test, img_size_target): # predict both orginal and reflect x\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(a) for a in model.predict(np.array([np.fliplr(x) for x in x_test])).reshape(-1, img_size_target, img_size_target)])\n",
    "    return preds_test / 2.0\n",
    "\n",
    "def filter_image(img):\n",
    "    if img.sum() < 100:\n",
    "        return np.zeros(img.shape)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "model_filepaths = [\n",
    "    '.\\\\007-model-resnet-fold-0.hdf5',\n",
    "    '.\\\\007-model-resnet-fold-1.hdf5',\n",
    "    '.\\\\007-model-resnet-fold-2.hdf5',\n",
    "    '.\\\\007-model-resnet-fold-3.hdf5',\n",
    "    '.\\\\007-model-resnet-fold-4.hdf5'\n",
    "]\n",
    "\n",
    "threshold_best_stack = [0.5133333333333333, 0.38, 0.43333333333333335, 0.36666666666666664, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "\n",
    "train_df = pd.read_csv(\"./data/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"./data/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273bd25ffaa44623958d652d0815d82a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([(np.array(load_img(\"./data/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 101, 101)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test = np.zeros((18000,101,101))\n",
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\007-model-resnet-fold-0.hdf5 0.5133333333333333\n",
      "(18000, 101, 101) (18000, 101, 101)\n",
      ".\\007-model-resnet-fold-1.hdf5 0.38\n",
      "(18000, 101, 101) (18000, 101, 101)\n",
      ".\\007-model-resnet-fold-2.hdf5 0.43333333333333335\n",
      "(18000, 101, 101) (18000, 101, 101)\n",
      ".\\007-model-resnet-fold-3.hdf5 0.36666666666666664\n",
      "(18000, 101, 101) (18000, 101, 101)\n",
      ".\\007-model-resnet-fold-4.hdf5 0.3\n",
      "(18000, 101, 101) (18000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "# bld\n",
    "for model_filepath, threshold_best in zip(model_filepaths, threshold_best_stack):\n",
    "    print(model_filepath, threshold_best)\n",
    "    model = load_model(model_filepath)\n",
    "    pred_temp = predict_result(model, x_test, img_size_target)\n",
    "    print(pred_temp.shape, preds_test.shape)\n",
    "    preds_test += pred_temp\n",
    "    \n",
    "preds_test = preds_test > sum(threshold_best_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\007-model-resnet-fold-0.hdf5 0.5133333333333333\n",
      "(18000, 101, 101) (18000, 101, 101)\n",
      ".\\007-model-resnet-fold-1.hdf5 0.38\n",
      "(18000, 101, 101) (18000, 101, 101)\n",
      ".\\007-model-resnet-fold-2.hdf5 0.43333333333333335\n",
      "(18000, 101, 101) (18000, 101, 101)\n",
      ".\\007-model-resnet-fold-3.hdf5 0.36666666666666664\n",
      "(18000, 101, 101) (18000, 101, 101)\n",
      ".\\007-model-resnet-fold-4.hdf5 0.3\n",
      "(18000, 101, 101) (18000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "# vote\n",
    "for model_filepath, threshold_best in zip(model_filepaths, threshold_best_stack):\n",
    "    print(model_filepath, threshold_best)\n",
    "    model = load_model(model_filepath)\n",
    "    pred_temp = (predict_result(model, x_test, img_size_target) > threshold_best)\n",
    "    print(pred_temp.shape, preds_test.shape)\n",
    "    preds_test += pred_temp\n",
    "    \n",
    "preds_test = preds_test >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode2(im):\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2045ea430be4daf90134b98c873350d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usedtime = 8.09692645072937 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode2(filter_image(preds_test[i])) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('./result/007-submission-bld.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rle_mask</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353e010b7b</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5439dbbddf</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71bab9f311</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52551f7a80</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512d8d9997</th>\n",
       "      <td>3 1 102 1 104 1 203 5 304 3 405 6 506 3 510 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64dba827d6</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0a3a8a5f37</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329563756f</th>\n",
       "      <td>1 4948 4950 100 5051 99 5152 98 5253 97 5354 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6cba2e890</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989c646373</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     rle_mask\n",
       "id                                                           \n",
       "353e010b7b                                                   \n",
       "5439dbbddf                                                   \n",
       "71bab9f311                                                   \n",
       "52551f7a80                                                   \n",
       "512d8d9997  3 1 102 1 104 1 203 5 304 3 405 6 506 3 510 1 ...\n",
       "64dba827d6                                                   \n",
       "0a3a8a5f37                                                   \n",
       "329563756f  1 4948 4950 100 5051 99 5152 98 5253 97 5354 9...\n",
       "f6cba2e890                                                   \n",
       "989c646373                                                   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rle_mask</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353e010b7b</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5439dbbddf</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71bab9f311</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52551f7a80</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512d8d9997</th>\n",
       "      <td>94 8 194 9 296 8 396 9 495 11 595 12 696 12 79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64dba827d6</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0a3a8a5f37</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329563756f</th>\n",
       "      <td>1 9077 9084 91 9189 83 9293 76 9394 71 9495 66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6cba2e890</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989c646373</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     rle_mask\n",
       "id                                                           \n",
       "353e010b7b                                                   \n",
       "5439dbbddf                                                   \n",
       "71bab9f311                                                   \n",
       "52551f7a80                                                   \n",
       "512d8d9997  94 8 194 9 296 8 396 9 495 11 595 12 696 12 79...\n",
       "64dba827d6                                                   \n",
       "0a3a8a5f37                                                   \n",
       "329563756f  1 9077 9084 91 9189 83 9293 76 9394 71 9495 66...\n",
       "f6cba2e890                                                   \n",
       "989c646373                                                   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "907px",
    "left": "0px",
    "right": "1633px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
